•	pandas: for data manipulation
•	numpy: for numerical operations
•	matplotlib and seaborn: for data visualization
•	scikit-learn: for machine learning algorithms and evaluation
•	imblearn: for handling class imbalance

import pandas as pd

# Load the dataset
data = pd.read_csv('creditcard.csv')

# Check the first few rows of the dataset
print(data.head())

# Check the summary of the dataset (including null values and data types)
print(data.info())

# Check for class distribution
print(data['Class'].value_counts())
# Check for missing values
print(data.isnull().sum())
from sklearn.preprocessing import StandardScaler

# Drop the 'Time' and 'Class' column (Time is just a timestamp and not useful for modeling)
X = data.drop(columns=['Class', 'Time'])
y = data['Class']

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
from imblearn.over_sampling import SMOTE

# Apply SMOTE to oversample the minority class
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_scaled, y)

# Check the class distribution after resampling
print(pd.Series(y_res).value_counts())
from sklearn.model_selection import train_test_split

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)

print(f"Training set size: {X_train.shape[0]}")
print(f"Testing set size: {X_test.shape[0]}")
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Initialize the Logistic Regression model
lr_model = LogisticRegression(random_state=42)

# Train the model
lr_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_lr = lr_model.predict(X_test)

# Evaluate the model
print("Logistic Regression Classification Report:")
print(classification_report(y_test, y_pred_lr))

# ROC-AUC score
roc_auc_lr = roc_auc_score(y_test, y_pred_lr)
print(f"ROC-AUC Score: {roc_auc_lr:.2f}")
from sklearn.ensemble import RandomForestClassifier

# Initialize the Random Forest model
rf_model = RandomForestClassifier(random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_rf = rf_model.predict(X_test)

# Evaluate the model
print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))

# ROC-AUC score
roc_auc_rf = roc_auc_score(y_test, y_pred_rf)
print(f"ROC-AUC Score: {roc_auc_rf:.2f}")
import xgboost as xgb

# Initialize the XGBoost model
xgb_model = xgb.XGBClassifier(random_state=42)

# Train the model
xgb_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_xgb = xgb_model.predict(X_test)

# Evaluate the model
print("XGBoost Classification Report:")
print(classification_report(y_test, y_pred_xgb))

# ROC-AUC score
roc_auc_xgb = roc_auc_score(y_test, y_pred_xgb)
print(f"ROC-AUC Score: {roc_auc_xgb:.2f}")
import xgboost as xgb

# Initialize the XGBoost model
xgb_model = xgb.XGBClassifier(random_state=42)

# Train the model
xgb_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_xgb = xgb_model.predict(X_test)

# Evaluate the model
print("XGBoost Classification Report:")
print(classification_report(y_test, y_pred_xgb))

# ROC-AUC score
roc_auc_xgb = roc_auc_score(y_test, y_pred_xgb)
print(f"ROC-AUC Score: {roc_auc_xgb:.2f}")
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Plot ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_rf)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()
  from sklearn.model_selection import GridSearchCV

# Hyperparameter grid for Random Forest
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20],
    'min_samples_split': [2, 5]
}

# Initialize GridSearchCV
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='roc_auc')

# Fit grid search
grid_search.fit(X_train, y_train)

# Best parameters and best score
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)
import joblib

# Save the Random Forest model
joblib.dump(rf_model, 'credit_card_fraud_detection_model.pkl')

